# -*- coding: utf-8 -*-
"""RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-qDhZ_2viv-3eyrizsMwrKAyXLaZPag
"""

pip install -q langchain langchain_core langchain_community sentence_transformers faiss-cpu unstructured Cython tiktoken unstructured[local-inference] langchain_groq

import getpass
import os
if "GROQ_API_KEY" not in os.environ:
    os.environ["GROQ_API_KEY"] = getpass.getpass("Provide API Key ")

from langchain.document_loaders import TextLoader
loader = TextLoader('/content/About India, cricket (4).txt')
documents=loader.load()

!pip install langchain_community

import textwrap

def wrap_text_preserve_newlines(text, width=110):
    # Split the input text into lines based on newline character
    lines = text.split('\n')

    # Wrap each line individually
    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]

    # Join  the wrapped lines back together with
    wrapped_text = '\n'.join(wrapped_lines)

    return wrapped_text

print(wrap_text_preserve_newlines(str(documents[0])))

#Text split
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

len(docs)

docs[8]

from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings()

from langchain.vectorstores import FAISS

db = FAISS.from_documents(docs, embeddings)

import os
from langchain_groq import ChatGroq
from google.colab import userdata

#Ensure GROQ_API_KEY is set in environment variables
if "GROQ_API_KEY" not in os.environ:
    os.environ["GROQ_API_KEY"] = userdata.get("GROQ_API_KEY")

Groq_LLM = ChatGroq(
           api_key = os.getenv(""),
           model_name = "gemma2-9b-it"
)

pip install langchain_groq

from langchain.chains.question_answering import load_qa_chain

chain = load_qa_chain(Groq_LLM, chain_type="stuff")

query = "What makes India a land of diversity?"
docs = db.similarity_search(query)
chain.run(input_documents=docs, question=query)